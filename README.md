# A Note of Study
## 2016-12
* Generative Adversarial Net([NIPS](https://arxiv.org/abs/1406.2661))
* Visualizing Data using t-SNE([JMLR](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf))
* Accelerating t-SNE using Tree-Based Algorithms([JMLR](http://www.jmlr.org/papers/v15/vandermaaten14a.html))
* Semi-Supervised Learning with Ladder Networks([NIPS](https://papers.nips.cc/paper/5947-semi-supervised-learning-with-ladder-networks))
* Deep learning([NATURE](http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html))
* Expectation–Maximization Approach toFault Diagnosis With Missing Data([IEEE](http://ieeexplore.ieee.org/document/6850032/?arnumber=6850032&tag=1))
* A Few Useful Things to Know about Machine Learning([CACM](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf))
* Variational Inference
* Auto-Encoding Variational Bayes([arxiv](https://arxiv.org/abs/1312.6114))
* Gaussian Mixture Models
* Contractive Auto-Encoders:Explicit Invariance During Feature Extraction([ICML](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Rifai_455.pdf))
* Dimensionality Reduction: A Comparative Review([JMLR](https://www.tilburguniversity.edu/upload/59afb3b8-21a5-4c78-8eb3-6510597382db_TR2009005.pdf))
* Machine learning Foundations:A Case Study Approach([***coursera***](https://www.coursera.org/learn/ml-foundations/home/welcome))  
* Machine Learning: Regression([***coursera***](https://www.coursera.org/learn/ml-regression/home))
* Machine Learning: Classification([***coursera***](https://www.coursera.org/learn/ml-classification/home))  
* Probabilistic Graphical Models 1: Representation([***coursera***](https://www.coursera.org/learn/probabilistic-graphical-models/home/welcome))  
* 机器学习技法 : lecture 11.13
* Oxford Deep learning 

    Deep Learning Lecture 4- Regularization, model complexity and data complexity (part 1)
    
* Ruslan Salakhutdinov Department of Statistical Sciences, **University of Toronto** 

  Deep Learning part1([***videolectures***](http://videolectures.net/kdd2014_salakhutdinov_deep_learning/)) 
* Java Programming and Software Engineering Fundamentals **Duke University** ***coursera***

  Course 1: [Programming Foundations with JavaScript, HTML and CSS](https://www.coursera.org/learn/duke-programming-web/home/welcome)
## 2017-3
* Exploiting Expertise Rules for Statistical Data-Driven Modeling
* Wasserstein GAN([arxiv](https://arxiv.org/abs/1701.07875))
* Java Programming and Software Engineering Fundamentals **Duke University** ***coursera***

  Course 2: [Java Programming: Solving Problems with Software](https://www.coursera.org/learn/java-programming/home/welcome)
* 机器学习技法 : lecture 1
* DAE && Multi-layer DAE
* Embedding AE(feauture && reconstruct)
* AAE(simple implement)
* W-GAN(simple implement)
## 2017-4
* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift([arxiv](https://arxiv.org/pdf/1502.03167.pdf))
* Dropout: A Simple Way to Prevent Neural Networks from Overfitting([JMLR](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf))
* U-Net: Convolutional Networks for BiomedicalImage Segmentation([arxiv](https://arxiv.org/pdf/1505.04597.pdf))
* Improved Training of Wasserstein GANs([arxiv](https://arxiv.org/abs/1704.00028))
* Backpropagation(I.II)([cs213n](http://study.163.com/course/courseMain.htm?courseId=1003223001))
* Convolutional Neural Networks(I.II)([cs213n](http://study.163.com/course/courseMain.htm?courseId=1003223001))
* Training Neural Networks part I([cs213n](http://study.163.com/course/courseMain.htm?courseId=1003223001))
* Training Neural Networks part II([cs213n](http://study.163.com/course/courseMain.htm?courseId=1003223001))
* Understanding and visualizing Convolutional Neural Networks([cs213n](http://study.163.com/course/courseMain.htm?courseId=1003223001))
* Selection Sort
* Insertion Sort
* Shell Sort
* Binary Tree
## 2017-5
* On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes([NIPS](https://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf))
* InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets([arxiv](https://arxiv.org/abs/1606.03657))
* Softmax GAN([arxiv](https://arxiv.org/abs/1704.06191))
* Gang of GANs:Generative Adversarial Networks with Maximum Margin Ranking([arxiv](https://arxiv.org/abs/1704.04865))
* Autoencoding beyond pixels using a learned similarity metric([arxiv](https://arxiv.org/pdf/1512.09300.pdf))
* Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks([arxiv](https://arxiv.org/pdf/1511.06434.pdf))
* Adversarially Learned Inference([arxiv](https://arxiv.org/pdf/1606.00704.pdf))
* Conditional Image Generation with PixelCNN Decoders([NIPS](https://arxiv.org/pdf/1606.05328.pdf))
* 机器学习技法 : lecture 2.3.4.5.6.7.8


 